# InstiGPT Faculty Scraper

**AI-powered universal faculty data scraper** that extracts professor profiles from any university website and enriches them with Google Scholar metrics.

## ğŸš€ Key Features

- **ğŸ” Universal Auto-Discovery**: Auto-detects faculty pages via sitemap, DuckDuckGo search, or deep crawling
- **ğŸ“¸ Vision Analysis**: Uses GPT-4o-mini to classify pages (directory, gateway, profile, blocked)
- **âš¡ Multi-Fallback Extraction**: CSS selectors â†’ LLM extraction â†’ Pagination handling
- **ğŸ“ Google Scholar Linking**: Enriches profiles with H-Index, citations, top papers
- **ğŸ›¡ï¸ Block Detection**: Detects CAPTCHA, Cloudflare, login walls automatically
- **ğŸ“‹ University Profiles**: Pre-configured URLs/selectors for Princeton, MIT, Stanford, IITs
- **ğŸ“¦ Batch Processing**: Process hundreds of universities from an Excel sheet

## ğŸ› ï¸ Installation

Prerequisites: `python >= 3.10`, `uv` (recommended).

```bash
# 1. Create and activate virtual environment
uv venv .venv
source .venv/bin/activate

# 2. Install dependencies (editable mode recommended for dev)
uv pip install -e .

# 3. Setup browser for Crawl4AI
python -m playwright install chromium
```

## âš™ï¸ Configuration

Create a `.env` file or export environment variables:

### Option A: OpenAI (Recommended)
```bash
export OPENAI_API_KEY="sk-..."
```

### Option B: Ollama (Free/Local)
```bash
ollama serve
ollama pull llama3.1:8b

export OLLAMA_BASE_URL="http://localhost:11434"
```

## ğŸ“– Usage

### 1. Scrape a University
```bash
# Basic scrape with enrichment
python -m insti_scraper scrape "https://princeton.edu"

# Skip Google Scholar enrichment (faster)
python -m insti_scraper scrape "https://mit.edu" --no-enrich
```

### 2. Discover Faculty Pages Only
```bash
python -m insti_scraper discover "https://stanford.edu"
```

### 3. Batch Process from Excel
```bash
python -m insti_scraper batch universities.xlsx --output ./results
```

### 4. List Database Content
```bash
python -m insti_scraper list
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DISCOVERY PHASE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Check University Profiles (YAML config)                     â”‚
â”‚  2. DuckDuckGo Search (site:domain + faculty keywords)          â”‚
â”‚  3. Sitemap Parsing                                             â”‚
â”‚  4. Deep Crawling (BFS with keyword scoring)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        EXTRACTION PHASE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Vision Analysis: Classify page type (A-F, Z)                â”‚
â”‚     - Type A: Full directory â†’ Extract directly                 â”‚
â”‚     - Type C: Gateway â†’ Crawl department links                  â”‚
â”‚     - Type D: Paginated â†’ Use pagination handler                â”‚
â”‚     - Type F: Individual â†’ Skip or extract single               â”‚
â”‚  2. Multi-Fallback Selectors: DataTables, Cards, Grids          â”‚
â”‚  3. LLM Extraction: GPT-4o for complex layouts                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ENRICHMENT PHASE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Google Scholar â†’ H-Index, Citations, Top Papers                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‚ Project Structure

```
insti_scraper/
â”œâ”€â”€ config/                   # University profiles & config
â”‚   â”œâ”€â”€ university_profiles.yaml
â”‚   â””â”€â”€ profile_loader.py
â”œâ”€â”€ core/                     # Core utilities
â”‚   â”œâ”€â”€ config.py             # Settings
â”‚   â”œâ”€â”€ retry_wrapper.py      # Exponential backoff
â”‚   â”œâ”€â”€ selector_strategies.py # Multi-fallback CSS
â”‚   â””â”€â”€ auto_config.py        # Pagination detection
â”œâ”€â”€ discovery/                # Page discovery
â”‚   â”œâ”€â”€ discovery.py          # FacultyPageDiscoverer
â”‚   â””â”€â”€ duckduckgo_discovery.py
â”œâ”€â”€ handlers/                 # Page type handlers
â”‚   â”œâ”€â”€ page_handlers.py      # Abstract handlers
â”‚   â””â”€â”€ pagination_handler.py
â”œâ”€â”€ services/                 # Business logic
â”‚   â”œâ”€â”€ extraction_service.py # LLM extraction
â”‚   â”œâ”€â”€ enrichment_service.py # Scholar enrichment
â”‚   â””â”€â”€ vision_analyzer.py    # Screenshot analysis
â”œâ”€â”€ domain/                   # Data models
â”‚   â””â”€â”€ models.py             # University, Dept, Professor
â”œâ”€â”€ database/                 # Persistence
â”‚   â””â”€â”€ crud.py
â””â”€â”€ main.py                   # CLI entrypoint
```

## ğŸ§ª Running Tests

```bash
# Run all tests
pytest tests/ -v

# Run integration tests only
pytest tests/test_integration.py -v
```

## ğŸ“„ License
MIT
